server.port=6806
#logging.config=classpath:log4j2.xml

server.tomcat.accesslog.enabled = true
server.tomcat.accesslog.pattern=%{yyyy-MM-dd HH:mm:ss}t %h %l %u %t %r %s %b %{Referer}i %{User-Agent}i
server.tomcat.basedir=../logs
server.tomcat.accesslog.suffix=.log
server.tomcat.accesslog.rotate=true
server.tomcat.accesslog.file-date-format=yyyy-MM/dd



spring.application.name=server-kafka
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.0.184:9092
#=============== provider  =======================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#=============== consumer  =======================
# 指定默认消费者group id
#spring.kafka.consumer.group-id=user-log-group
#      earliest   当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
#      latest     当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
#      none       topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=earliest
# 默认true true是 kafka 管理自动提交 false是手动提交，假如没有手动提交 spring 会转换成自动提交
spring.kafka.consumer.enable-auto-commit=false
#在自动提交为false时
spring.kafka.listener.ack-mode=manual
# 默认 5000ms consumer 拿到之后5s 后 offset
spring.kafka.consumer.auto-commit-interval=100ms
spring.session.timeout=30000ms
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#=======set comsumer max fetch.byte 2*1024*1024=============
spring.kafka.consumer.properties.max.partition.fetch.bytes=2097152